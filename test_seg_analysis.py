"""
SEG ë¶„ì„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì„¤ì¹˜ ë° ë™ì‘ì„ í™•ì¸í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
"""

import numpy as np
import pandas as pd
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
# project_root = Path(__file__).parent.parent
# sys.path.insert(0, str(project_root))

from src.seg_analysis import SurveillanceErrorGrid, evaluate_seg_for_model


def test_seg_classification():
    """SEG Zone ë¶„ë¥˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("TEST 1: SEG Zone Classification")
    print("="*80)
    
    seg = SurveillanceErrorGrid()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        # (reference, prediction, expected_zone)
        (100, 100, "None-Risk"),            # ì™„ë²½í•œ ì˜ˆì¸¡, diff=0
        (100, 110, "Slight-Risk-Upper"),    # ì •ìƒ êµ¬ê°„, rel_diff=10% -> Slight-Upper
        (100, 90, "Slight-Risk-Lower"),     # ì •ìƒ êµ¬ê°„, rel_diff=10% -> Slight-Lower
        (60, 80, "Moderate-Risk-Lower"),    # ì €í˜ˆë‹¹(<70), abs_diff=20 -> Moderate (15<20<25)
        (200, 250, "Great-Risk-Upper"),     # ê³ í˜ˆë‹¹(>180), abs_diff=50 -> Great (45<50<65)
        (70, 30, "Extreme-Risk-Lower"),     # ì €í˜ˆë‹¹(<70), abs_diff=40 -> Extreme (>35)
        (180, 260, "Extreme-Risk-Upper"),   # ê³ í˜ˆë‹¹(>180), abs_diff=80 -> Extreme (>65)
    ]
    
    print("\nTest Cases:")
    print(f"{'Reference':>12} {'Predicted':>12} {'Expected Zone':>25} {'Actual Zone':>25} {'Status':>10}")
    print("-" * 100)
    
    passed = 0
    failed = 0
    
    for ref, pred, expected in test_cases:
        actual = seg.classify_seg_zone(ref, pred)
        status = "âœ“ PASS" if actual == expected else "âœ— FAIL"
        
        if status == "âœ“ PASS":
            passed += 1
        else:
            failed += 1
        
        print(f"{ref:>12.1f} {pred:>12.1f} {expected:>25} {actual:>25} {status:>10}")
    
    print("\n" + "="*80)
    print(f"Results: {passed} passed, {failed} failed")
    print("="*80 + "\n")
    
    return failed == 0


def test_seg_analysis():
    """ì „ì²´ SEG ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("TEST 2: SEG Analysis with Synthetic Data")
    print("="*80)
    
    # í•©ì„± ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 500
    
    # ê° êµ¬ê°„ë³„ ìƒ˜í”Œ ìˆ˜ ì •í™•íˆ ê³„ì‚°
    n_low = n_samples // 3  # 166
    n_normal = n_samples // 3  # 166
    n_high = n_samples - n_low - n_normal  # 168 (ë‚˜ë¨¸ì§€)
    
    # ë‹¤ì–‘í•œ í˜ˆë‹¹ ë²”ìœ„ì˜ ë°ì´í„° ìƒì„±
    y_true = np.concatenate([
        np.random.uniform(50, 70, n_low),     # ì €í˜ˆë‹¹
        np.random.uniform(70, 180, n_normal), # ì •ìƒ
        np.random.uniform(180, 300, n_high)   # ê³ í˜ˆë‹¹
    ])
    
    # ì˜ˆì¸¡ê°’ ìƒì„± (ì‹¤ì œê°’ + ë…¸ì´ì¦ˆ)
    noise = np.random.normal(0, 15, n_samples)
    y_pred = y_true + noise
    y_pred = np.clip(y_pred, 40, 350)  # í•©ë¦¬ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
    
    print(f"\nSynthetic Data Generated:")
    print(f"  - Samples: {n_samples}")
    print(f"  - Reference BG range: {y_true.min():.1f} - {y_true.max():.1f} mg/dL")
    print(f"  - Predicted BG range: {y_pred.min():.1f} - {y_pred.max():.1f} mg/dL")
    
    # SEG ë¶„ì„ ìˆ˜í–‰
    seg = SurveillanceErrorGrid()
    zones, statistics = seg.analyze_seg(y_true, y_pred)
    
    print("\nSEG Statistics:")
    print("-" * 80)
    print(f"{'Zone':<30} {'Percentage':>15}")
    print("-" * 80)
    
    # ì£¼ìš” í†µê³„ ì¶œë ¥
    key_stats = [
        'None-Risk',
        'Total-Slight-Risk',
        'Total-Moderate-Risk',
        'Total-Great-Risk',
        'Total-Extreme-Risk',
        'Clinically-Acceptable'
    ]
    
    for stat in key_stats:
        if stat in statistics:
            print(f"{stat:<30} {statistics[stat]:>14.2f}%")
    
    print("-" * 80)
    
    # ì„ìƒì  í—ˆìš© ê¸°ì¤€ ê²€ì‚¬
    acceptable = statistics['Clinically-Acceptable']
    extreme = statistics['Total-Extreme-Risk']
    
    print(f"\nClinical Evaluation:")
    if acceptable >= 85:
        print(f"  âœ“ Clinically-Acceptable: {acceptable:.2f}% (â‰¥85% target) - GOOD")
    else:
        print(f"  âš  Clinically-Acceptable: {acceptable:.2f}% (<85% target) - NEEDS IMPROVEMENT")
    
    if extreme <= 1:
        print(f"  âœ“ Extreme-Risk: {extreme:.2f}% (â‰¤1% target) - SAFE")
    else:
        print(f"  âš  Extreme-Risk: {extreme:.2f}% (>1% target) - CAUTION")
    
    print("\n" + "="*80 + "\n")
    
    return zones, statistics


def test_seg_visualization():
    """SEG ì‹œê°í™” í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("TEST 3: SEG Visualization")
    print("="*80)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 300
    
    y_true = np.random.uniform(60, 250, n_samples)
    y_pred = y_true + np.random.normal(0, 20, n_samples)
    y_pred = np.clip(y_pred, 50, 300)
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    test_results_dir = Path("test_results")
    test_results_dir.mkdir(exist_ok=True)
    
    print(f"\nGenerating SEG visualizations...")
    print(f"Output directory: {test_results_dir}")
    
    # SEG ë¶„ì„ ë° ì‹œê°í™”
    seg = SurveillanceErrorGrid()
    zones, statistics = seg.analyze_seg(y_true, y_pred)
    
    # ì‹œê°í™” ì €ì¥
    plot_path = test_results_dir / "test_seg_plot.png"
    seg.plot_seg(
        y_true=y_true,
        y_pred=y_pred,
        zones=zones,
        model_name="Test Model",
        save_path=plot_path,
        title_suffix="TEST"
    )
    
    # ìš”ì•½ í…Œì´ë¸” ì €ì¥
    table_path = test_results_dir / "test_seg_summary.csv"
    summary_df = seg.create_seg_summary_table(
        statistics=statistics,
        model_name="Test Model",
        save_path=table_path
    )
    
    print("\nGenerated Files:")
    print(f"  âœ“ SEG Plot: {plot_path}")
    print(f"  âœ“ Summary Table: {table_path}")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if plot_path.exists() and table_path.exists():
        print("\nâœ“ All files created successfully!")
        return True
    else:
        print("\nâœ— File creation failed!")
        return False


def test_model_evaluation():
    """ì „ì²´ ëª¨ë¸ í‰ê°€ í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("TEST 4: Complete Model Evaluation with SEG")
    print("="*80)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 400
    
    # ê° êµ¬ê°„ë³„ ìƒ˜í”Œ ìˆ˜ ì •í™•íˆ ê³„ì‚°
    n_low = n_samples // 4  # 100
    n_normal = n_samples // 2  # 200
    n_high = n_samples - n_low - n_normal  # 100
    
    y_true = np.concatenate([
        np.random.uniform(50, 70, n_low),
        np.random.uniform(70, 180, n_normal),
        np.random.uniform(180, 280, n_high)
    ])
    
    # ë‘ ê°€ì§€ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
    models = {
        'Good Model': y_true + np.random.normal(0, 10, n_samples),
        'Poor Model': y_true + np.random.normal(0, 30, n_samples)
    }
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬
    test_results_dir = Path("test_results")
    
    print(f"\nEvaluating {len(models)} models...")
    
    all_results = {}
    
    for model_name, y_pred in models.items():
        y_pred = np.clip(y_pred, 40, 320)
        
        print(f"\n--- {model_name} ---")
        
        result = evaluate_seg_for_model(
            y_true=y_true,
            y_pred=y_pred,
            model_name=model_name,
            results_dir=test_results_dir,
            experiment_name="TEST"
        )
        
        all_results[model_name] = result
        
        # ì£¼ìš” ì§€í‘œ ì¶œë ¥
        stats = result['statistics']
        print(f"  Clinically-Acceptable: {stats['Clinically-Acceptable']:.2f}%")
        print(f"  Extreme-Risk: {stats['Total-Extreme-Risk']:.2f}%")
    
    # ë¹„êµ ì‹œê°í™”
    print("\nGenerating comparison plot...")
    
    all_statistics = {name: result['statistics'] for name, result in all_results.items()}
    
    comparison_path = test_results_dir / "test_seg_comparison.png"
    seg = SurveillanceErrorGrid()
    seg.plot_seg_comparison(
        all_statistics=all_statistics,
        save_path=comparison_path,
        title_suffix="TEST"
    )
    
    print(f"âœ“ Comparison plot saved: {comparison_path}")
    
    print("\n" + "="*80 + "\n")
    
    return all_results


def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print(" "*20 + "SEG ANALYSIS MODULE TEST SUITE")
    print("="*80 + "\n")
    
    test_results = []
    
    # í…ŒìŠ¤íŠ¸ 1: Zone ë¶„ë¥˜
    try:
        result = test_seg_classification()
        test_results.append(("Zone Classification", result))
    except Exception as e:
        print(f"âœ— Test 1 failed with error: {e}")
        test_results.append(("Zone Classification", False))
    
    # í…ŒìŠ¤íŠ¸ 2: SEG ë¶„ì„
    try:
        zones, stats = test_seg_analysis()
        test_results.append(("SEG Analysis", True))
    except Exception as e:
        print(f"âœ— Test 2 failed with error: {e}")
        test_results.append(("SEG Analysis", False))
    
    # í…ŒìŠ¤íŠ¸ 3: ì‹œê°í™”
    try:
        result = test_seg_visualization()
        test_results.append(("Visualization", result))
    except Exception as e:
        print(f"âœ— Test 3 failed with error: {e}")
        test_results.append(("Visualization", False))
    
    # í…ŒìŠ¤íŠ¸ 4: ëª¨ë¸ í‰ê°€
    try:
        results = test_model_evaluation()
        test_results.append(("Model Evaluation", True))
    except Exception as e:
        print(f"âœ— Test 4 failed with error: {e}")
        test_results.append(("Model Evaluation", False))
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print(" "*25 + "TEST SUMMARY")
    print("="*80)
    
    print(f"\n{'Test Name':<30} {'Result':>20}")
    print("-" * 80)
    
    passed_count = 0
    total_count = len(test_results)
    
    for test_name, passed in test_results:
        status = "âœ“ PASSED" if passed else "âœ— FAILED"
        print(f"{test_name:<30} {status:>20}")
        if passed:
            passed_count += 1
    
    print("-" * 80)
    print(f"Total: {passed_count}/{total_count} tests passed")
    print("="*80 + "\n")
    
    if passed_count == total_count:
        print("ğŸ‰ All tests passed! SEG analysis module is ready to use.")
        print("\nNext steps:")
        print("1. Review the generated files in 'test_results/' directory")
        print("2. Follow SEG_INTEGRATION_GUIDE.md to integrate into your pipeline")
        print("3. Run your actual experiments with SEG analysis enabled")
    else:
        print("âš  Some tests failed. Please review the error messages above.")
    
    return passed_count == total_count


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)