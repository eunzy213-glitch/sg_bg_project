# models.py
# ============================================================
# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ/ì˜ˆì¸¡ ìœ í‹¸
# ============================================================

import numpy as np # ìˆ˜ì¹˜ì—°ì‚° ë° ì¸ë±ìŠ¤ ë°°ì—´ ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬
import logging     # âœ… ë¡œê·¸ ì¶œë ¥ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¶”ê°€)
from sklearn.model_selection import train_test_split # ë°ì´í„°ë¥¼ train/testë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜

# ------------------------------------------------------------
# âœ… Logger ì„¤ì • (ì¶”ê°€)
# ------------------------------------------------------------
logger = logging.getLogger(__name__)


def get_model_dict():
    from sklearn.linear_model import LinearRegression, HuberRegressor # ì„ í˜•íšŒê·€ ë° Huber íšŒê·€
    from sklearn.preprocessing import PolynomialFeatures # ë‹¤í•­ Feature ìƒì„±
    from sklearn.pipeline import Pipeline # ì „ì²˜ë¦¬+ëª¨ë¸ì„ í•œë²ˆì— ë¬¶ëŠ” íŒŒì´í”„ë¼ì¸
    from sklearn.ensemble import RandomForestRegressor # ëœë¤í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸
    from lightgbm import LGBMRegressor # LightGBM íšŒê·€ ëª¨ë¸

    logger.info("ğŸ”¹ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì‹œì‘")

    model_dict = { # ëª¨ë¸ë“¤ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
        "Linear": LinearRegression(), # ê¸°ë³¸ ì„ í˜•íšŒê·€ ëª¨ë¸

        "Polynomial": Pipeline([ # ë‹¤í•­ íšŒê·€ ëª¨ë¸ (3ì°¨ ë‹¤í•­ì‹)
            ("poly", PolynomialFeatures(degree=3)),
            ("lr", LinearRegression())
        ]),

        "Huber": HuberRegressor(), # Huber íšŒê·€ ëª¨ë¸ (ì´ìƒì¹˜ì— ê°•ê±´)

        "RandomForest": RandomForestRegressor( # ëœë¤í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸
            n_estimators=300,
            random_state=42,
            n_jobs=1
        ),

        "LightGBM": LGBMRegressor(
            n_estimators=500,
            learning_rate=0.05,
            random_state=42,
            subsample=1.0,
            colsample_bytree=1.0,
            deterministic=True,
            force_row_wise=True
        )
    }

    logger.info(f"ğŸ”¹ ì‚¬ìš© ëª¨ë¸ ëª©ë¡: {list(model_dict.keys())}")

    return model_dict



def train_and_predict_all(X, y, models, test_size=0.2, random_state=42): # ëª¨ë“  ëª¨ë¸ì„ í•™ìŠµí•˜ê³  test set ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜

    logger.info("ğŸ”¹ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘")
    logger.info(f"ğŸ”¹ ì…ë ¥ ë°ì´í„° shape: X={X.shape}, y={y.shape}")

    # --------------------------------------------------------
    # train / test split
    # --------------------------------------------------------
    indices = np.arange(len(X)) # 0 ~ N-1ê¹Œì§€ ì¸ë±ìŠ¤ ë°°ì—´ ìƒì„±

    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split( # train_tset_splitìœ¼ë¡œ x, y, indicesë¥¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‚˜ëˆ”
        X,
        y,
        indices,
        test_size=test_size,
        random_state=random_state
    )

    logger.info(
        f"ğŸ”¹ Train/Test split ì™„ë£Œ | "
        f"Train={X_train.shape[0]}, Test={X_test.shape[0]}"
    )

    preds = {} # ëª¨ë¸ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬

    # --------------------------------------------------------
    # ëª¨ë¸ë³„ í•™ìŠµ ë° ì˜ˆì¸¡
    # --------------------------------------------------------
    for name, model in models.items(): # dictì˜ ëª¨ë¸ëª…, ëª¨ë¸ê°ì²´ ìˆœíšŒ
        logger.info(f"ğŸ”¹ ëª¨ë¸ í•™ìŠµ ì‹œì‘: {name}")

        model.fit(X_train, y_train) # ëª¨ë¸ í•™ìŠµ
        preds[name] = model.predict(X_test) # í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ê°’ ì €ì¥

        logger.info(
            f"ğŸ”¹ ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ: {name} | "
            f"ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜={len(preds[name])}"
        )

    # --------------------------------------------------------
    # ë°˜í™˜ êµ¬ì¡°
    # --------------------------------------------------------
    pred_pack = {
        "y_test": y_test, # í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ
        "preds": preds, # ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’ ë”•ì…”ë„ˆë¦¬
        "test_idx": idx_test   # ì›ë³¸ df ê¸°ì¤€ì˜ test í–‰ ì¸ë±ìŠ¤
    }

    logger.info("ğŸ”¹ ëª¨ë“  ëª¨ë¸ í•™ìŠµ/ì˜ˆì¸¡ ì™„ë£Œ")

    return pred_pack # í•™ìŠµ/ì˜ˆì¸¡ íŒ¨í‚¤ì§€ ë°˜í™˜
