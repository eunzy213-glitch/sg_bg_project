# pipeline.py
# ============================================================
# SG â†’ BG ì˜ˆì¸¡ ì „ì²´ íŒŒì´í”„ë¼ì¸
# - ì „ì²˜ë¦¬
# - ëª¨ë¸ í•™ìŠµ
# - í‰ê°€
# - ì‹œê°í™”
# - ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥ (Streamlit/ì¶”ë¡ ìš©)
# - K-Fold êµì°¨ê²€ì¦ ì‹œê°í™”
# - ìµœì¢… ì¶”ë¡  ëª¨ë¸(pkl) ì €ì¥
# ============================================================

import os # íŒŒì¼/í´ë” ê²½ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import shutil # í´ë” ì‹œìŠ¤í…œ ì‘ì—… ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd # DataFrame ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import joblib # í•™ìŠµëœ ëª¨ë¸ .pkl í˜•íƒœë¡œ ì €ì¥/ë¡œë“œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import logging # âœ… ë¡œê·¸ ì¶œë ¥ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¶”ê°€)

from src.feature_builder import build_features # ëª¨ë¸ì— ë„£ì„ x, y, feature_name ìƒì„± 
from src.preprocessing import preprocess_and_filter_outliers # ì „ì²˜ë¦¬ ì „ì²´ ë¡œì§ ì²˜ë¦¬
from src.models import get_model_dict, train_and_predict_all  # ëª¨ë¸ë“¤ì„ dict í˜•íƒœë¡œ ë°˜í™˜, í•™ìŠµ ë° ì˜ˆì¸¡ ìˆ˜í–‰ 
from src.evaluation import (evaluate_all_models_overall, kfold_evaluate_models) # ëª¨ë¸ë³„ ì„±ëŠ¥ì§€í‘œ ë°˜í™˜, k-fold êµì°¨ê²€ì¦ ìˆ˜í–‰
from src.visualization import (plot_scatter, plot_actual_vs_pred, plot_residual, plot_bland_altman, plot_cega, plot_model_metrics) # ì‹œê°í™” í•¨ìˆ˜ë“¤


# --------------------------------------------------------
# âœ… Logger ì„¤ì • (ì¶”ê°€)
# --------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger(__name__)


def run_pipeline(data_path, experiment_name, feature_mode):
    """
    í•˜ë‚˜ì˜ ì‹¤í—˜(SG_ONLY / SG_PLUS_META)ì„
    ì²˜ìŒë¶€í„° ëê¹Œì§€ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸
    """

    logger.info(f"ğŸš€ Pipeline ì‹œì‘ | experiment={experiment_name}, feature_mode={feature_mode}")

    try:  # âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ë³´í˜¸ (ì¶”ê°€)

        # --------------------------------------------------------
        # 0ï¸âƒ£ ê²°ê³¼ í´ë” ì´ˆê¸°í™”
        # --------------------------------------------------------
        results_dir = os.path.join("results", experiment_name) # ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ìƒì„±

        if os.path.exists(results_dir): # ì¬ì‹¤í–‰ ì‹œ ê¸°ì¡´ ê²°ê³¼ ì‚­ì œ
            logger.warning(f"âš ï¸ ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ: {results_dir}")
            try:  # âœ… PermissionError ë°©ì–´ (ì¶”ê°€)
                shutil.rmtree(results_dir)
            except PermissionError as e:
                logger.error(f"âŒ ê²°ê³¼ í´ë” ì‚­ì œ ì‹¤íŒ¨ (ê¶Œí•œ ë¬¸ì œ): {e}")
                raise e

        os.makedirs(results_dir, exist_ok=True) # í´ë” ìƒì„±
        logger.info(f"ğŸ“ ê²°ê³¼ í´ë” ìƒì„± ì™„ë£Œ: {results_dir}")

        # --------------------------------------------------------
        # 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
        # --------------------------------------------------------
        logger.info(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì‹œì‘: {data_path}")
        df = pd.read_csv(data_path) # ì›ë³¸ë°ì´í„° ë¡œë“œ
        logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ | rows={len(df)}, cols={len(df.columns)}")

        # --------------------------------------------------------
        # 2ï¸âƒ£ ì œì™¸ ì»¬ëŸ¼ ì œê±°
        # --------------------------------------------------------
        drop_cols = [c for c in ["Gender", "Target_R"] if c in df.columns] # Gender, Target_R ì»¬ëŸ¼ ì œê±°
        df = df.drop(columns=drop_cols) # drop_colsì— ë“¤ì–´ìˆëŠ” ì»¬ëŸ¼ ì œê±°
        logger.info(f"ğŸ§¹ ì œê±°ëœ ì»¬ëŸ¼: {drop_cols}")

        # --------------------------------------------------------
        # 3ï¸âƒ£ ì „ì²˜ë¦¬ + ì´ìƒì¹˜ ì œê±°
        # --------------------------------------------------------
        logger.info("ğŸ§ª ì „ì²˜ë¦¬ ë° ì´ìƒì¹˜ ì œê±° ì‹œì‘")
        df_clean, filter_report = preprocess_and_filter_outliers(df) # ì „ì²˜ë¦¬ ë° ì´ìƒì¹˜ ì œê±° ìˆ˜í–‰

        # index ì •í•©ì„± ìœ ì§€
        df_clean = df_clean.reset_index(drop=True) # ì¸ë±ìŠ¤ ì¬ì •ë ¬

        filter_report.to_csv( # ì „ì²˜ë¦¬/ì´ìƒì¹˜ ì œê±° ë¦¬í¬íŠ¸ csv ì €ì¥
            os.path.join(results_dir, "filter_report.csv"),
            index=False
        )

        logger.info(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ | before={len(df)}, after={len(df_clean)}")

        # --------------------------------------------------------
        # 4ï¸âƒ£ Feature êµ¬ì„± (ëª¨ë¸ì— ë„£ì„ X, y ìƒì„±)
        # --------------------------------------------------------
        logger.info("ğŸ§© Feature êµ¬ì„± ì‹œì‘")
        X, y, feature_names = build_features(
            df_clean,
            mode=feature_mode
        )
        logger.info(f"âœ… Feature êµ¬ì„± ì™„ë£Œ | X.shape={X.shape}, feature_count={len(feature_names)}")

        # --------------------------------------------------------
        # 5ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ (train/test split ë‚´ë¶€ ì²˜ë¦¬)
        # --------------------------------------------------------
        models = get_model_dict() # ì‚¬ìš©í•  ëª¨ë¸ì„ dict í˜•íƒœë¡œ ë°›ì•„ì˜´
        logger.info(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸ ëª©ë¡: {list(models.keys())}")

        pred_pack = train_and_predict_all(X, y, models) # test setì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ë°˜í™˜
        logger.info("âœ… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì™„ë£Œ")

        # --------------------------------------------------------
        # 6ï¸âƒ£ ì„±ëŠ¥ í‰ê°€ (Hold-out Test)
        # --------------------------------------------------------
        logger.info("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
        overall_metrics = evaluate_all_models_overall(pred_pack) # ëª¨ë¸ë³„ ì„±ëŠ¥ì§€í‘œ ê³„ì‚°
        overall_metrics["experiment"] = experiment_name # ì‹¤í—˜ëª… ì»¬ëŸ¼ ì¶”ê°€

        overall_metrics.to_csv( # ëª¨ë¸ë³„ ì„±ëŠ¥ì§€í‘œ csv ì €ì¥
            os.path.join(results_dir, "overall_metrics.csv"),
            index=False
        )

        logger.info("âœ… ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ì €ì¥ ì™„ë£Œ")

        # --------------------------------------------------------
        # 7ï¸âƒ£ ì „ì²´ ë°ì´í„° ë¶„í¬ ì‹œê°í™”
        # --------------------------------------------------------
        logger.info("ğŸ“ˆ SG vs BG ì „ì²´ ì‚°ì ë„ ì‹œê°í™”")
        plot_scatter(df_clean, results_dir) # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ SG vs BG ì‚°ì ë„ ì‹œê°í™”

        y_true = pred_pack["y_test"] # ì‹¤ì œ BG ê°’ ê°€ì ¸ì˜´

        # --------------------------------------------------------
        # 8ï¸âƒ£ ëª¨ë¸ë³„ ì‹œê°í™” (ëª¨ë¸ë³„ í´ë”)
        # --------------------------------------------------------
        logger.info("ğŸ–¼ï¸ ëª¨ë¸ë³„ ì‹œê°í™” ìƒì„± ì‹œì‘")

        for model_name, y_pred in pred_pack["preds"].items(): # ëª¨ë¸ë§ˆë‹¤ ë°˜ë³µ
            logger.info(f"   â–¶ ì‹œê°í™” ìƒì„± ì¤‘: {model_name}")

            model_dir = os.path.join(results_dir, model_name) # ëª¨ë¸ë³„ í´ë” ê²½ë¡œ ìƒì„±
            os.makedirs(model_dir, exist_ok=True) # ëª¨ë¸ë³„ í´ë” ìƒì„±

            plot_actual_vs_pred(y_true, y_pred, model_name, model_dir)
            plot_residual(y_true, y_pred, model_name, model_dir)
            plot_bland_altman(y_true, y_pred, model_name, model_dir)
            plot_cega(y_true, y_pred, model_name, model_dir)

        # --------------------------------------------------------
        # 9ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ Bar Plot (R2 / RMSE / MAE / MARD)
        # --------------------------------------------------------
        logger.info("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ Bar Plot ìƒì„±")
        plot_model_metrics(overall_metrics, results_dir)

        # --------------------------------------------------------
        # ğŸ”Ÿ K-Fold êµì°¨ê²€ì¦ + ì‹œê°í™”
        # --------------------------------------------------------
        logger.info("ğŸ” K-Fold êµì°¨ê²€ì¦ ì‹œì‘")
        kfold_df = kfold_evaluate_models(df_clean, models)

        kfold_df.to_csv(
            os.path.join(results_dir, "kfold_metrics.csv"),
            index=False
        )

        logger.info("âœ… K-Fold ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

        # --------------------------------------------------------
        # 1ï¸âƒ£1ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥ (Streamlit / ë¶„ì„ìš©)
        # --------------------------------------------------------
        logger.info("ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ CSV ìƒì„± ì‹œì‘")

        pred_rows = [] # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        test_idx = pred_pack["test_idx"] # testë¡œ ì‚¬ìš©ëœ í–‰ ì¸ë±ìŠ¤ ëª©ë¡

        for model_name, y_pred in pred_pack["preds"].items():
            for i, idx in enumerate(test_idx):
                pred_rows.append({ 
                    "experiment": experiment_name,
                    "model": model_name,
                    "SG": df_clean.loc[idx, "SG"],
                    "y_true": y_true[i],
                    "y_pred": y_pred[i],
                    "residual": y_pred[i] - y_true[i],
                })

        pred_df = pd.DataFrame(pred_rows)

        pred_df.to_csv(
            os.path.join(results_dir, "predictions.csv"),
            index=False
        )

        logger.info("âœ… ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ")

        print(f"âœ… ì‹¤í—˜ ì™„ë£Œ (ì˜ˆì¸¡ CSV í¬í•¨): {experiment_name}")

        # --------------------------------------------------------
        # 1ï¸âƒ£2ï¸âƒ£ ìµœì  ëª¨ë¸ ì €ì¥ (ì¶”ë¡ ìš©)
        # - SG_PLUS_META ì‹¤í—˜ì—ì„œë§Œ ìˆ˜í–‰
        # - ì „ì²´ ë°ì´í„°(X, y)ë¡œ ì¬í•™ìŠµ
        # --------------------------------------------------------
        if experiment_name == "SG_PLUS_META":

            logger.info("ğŸ† ìµœì¢… LightGBM ëª¨ë¸ ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ")

            lgbm_model = get_model_dict()["LightGBM"]
            lgbm_model.fit(X, y)

            model_save_path = os.path.join(
                "results",
                "SG_PLUS_META",
                "best_model_lightgbm.pkl"
            )

            joblib.dump(lgbm_model, model_save_path)

            logger.info(f"âœ… ì¶”ë¡ ìš© ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

        logger.info(f"ğŸ‰ Pipeline ì¢…ë£Œ: {experiment_name}")

    except Exception as e:  # âœ… ì¹˜ëª…ì  ì˜¤ë¥˜ ë¡œê·¸
        logger.exception("ğŸ”¥ Pipeline ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ")
        raise e
