# pipelines/explain_pipeline.py
# ============================================================
# SHAP / LIME Explainability ì „ìš© íŒŒì´í”„ë¼ì¸
#
# ğŸ”‘ í•µì‹¬ ì„¤ê³„
# - í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸ê³¼ ë¶„ë¦¬
# - Explain ì „ìš© One-Hot Encoding ì‚¬ìš©
# - ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ë‹¨ìœ„ SHAP / LIME í•´ì„ ê°€ëŠ¥
#
# ê²°ê³¼ ì €ì¥ êµ¬ì¡°:
# results/
# â””â”€â”€ SG_PLUS_META/
#     â”œâ”€â”€ EXPLAIN_LightGBM/
#     â””â”€â”€ EXPLAIN_RandomForest/
# ============================================================

import os
import pandas as pd
import numpy as np

from src.preprocessing import preprocess_and_filter_outliers
from src.models import get_model_dict
from src.explainability import run_shap_analysis, run_lime_analysis


# ============================================================
# â­ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ê³„ì‚°
# ì´ íŒŒì¼ ìœ„ì¹˜: sg_bg_project/pipelines/explain_pipeline.py
# ============================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# BASE_DIR == sg_bg_project


# ============================================================
# â­ Explain ì „ìš© One-Hot Feature ìƒì„± í•¨ìˆ˜
# ============================================================
CATEGORICAL_COLS = [
    "Meal_Status",
    "BMI_Class",
    "Age_Group",
    "Exercise",
    "Family_History",
    "Pregnancy",
]


def build_explain_features(df: pd.DataFrame):
    """
    SHAP / LIME ì „ìš© feature ìƒì„±

    - SG: ìˆ˜ì¹˜í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ë²”ì£¼í˜• ë³€ìˆ˜: One-Hot Encoding
    - í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸ê³¼ ë¶„ë¦¬ëœ Explain ì „ìš© ì„¤ê³„
    """

    # --------------------------------------------------------
    # 1ï¸âƒ£ ìˆ˜ì¹˜í˜• Feature
    # --------------------------------------------------------
    X_num = df[["SG"]]

    # --------------------------------------------------------
    # 2ï¸âƒ£ ë²”ì£¼í˜• Feature â†’ One-Hot Encoding
    # --------------------------------------------------------
    X_cat = pd.get_dummies(
        df[CATEGORICAL_COLS],
        prefix=CATEGORICAL_COLS
    )

    # --------------------------------------------------------
    # 3ï¸âƒ£ ê²°í•©
    # --------------------------------------------------------
    X_explain = pd.concat([X_num, X_cat], axis=1)

    feature_names = X_explain.columns.tolist()

    return X_explain.values, feature_names


def run_explain_pipeline(
    data_path: str,
    experiment_name: str,
    target_models: list | None = None
):
    """
    SHAP / LIME ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸

    Parameters
    ----------
    data_path : str
        ì›ë³¸ ë°ì´í„° ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
        ì˜ˆ: "data/dataset.csv"
    experiment_name : str
        "SG_ONLY" or "SG_PLUS_META"
    target_models : list or None
        ì„¤ëª…í•  ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        ì˜ˆ) ["LightGBM", "RandomForest"]
        Noneì´ë©´ ëª¨ë“  ëª¨ë¸ ìˆ˜í–‰
    """

    # --------------------------------------------------------
    # 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ (ì‹¤í–‰ ìœ„ì¹˜ ë¬´ê´€)
    # --------------------------------------------------------
    data_path = os.path.join(BASE_DIR, data_path)
    df = pd.read_csv(data_path)

    # --------------------------------------------------------
    # 2ï¸âƒ£ ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
    # --------------------------------------------------------
    drop_cols = [c for c in ["Gender", "Target_R"] if c in df.columns]
    df = df.drop(columns=drop_cols)

    # --------------------------------------------------------
    # 3ï¸âƒ£ ì „ì²˜ë¦¬ + ì´ìƒì¹˜ ì œê±°
    # --------------------------------------------------------
    df_clean, _ = preprocess_and_filter_outliers(df)

    # index ì •í•©ì„± ìœ ì§€
    df_clean = df_clean.reset_index(drop=True)

    # --------------------------------------------------------
    # 4ï¸âƒ£ Explain ì „ìš© Feature êµ¬ì„± (â­ One-Hot)
    # --------------------------------------------------------
    # íƒ€ê¹ƒ
    y = df_clean["BG"].values

    # Explain ì „ìš© Feature
    X_explain, feature_names = build_explain_features(df_clean)

    # --------------------------------------------------------
    # 5ï¸âƒ£ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    # --------------------------------------------------------
    models = get_model_dict()

    if target_models is not None:
        models = {
            name: model
            for name, model in models.items()
            if name in target_models
        }

    # --------------------------------------------------------
    # 6ï¸âƒ£ Explain ê²°ê³¼ ì €ì¥ ë£¨íŠ¸
    # --------------------------------------------------------
    base_results_dir = os.path.join(
        BASE_DIR,
        "results",
        experiment_name
    )
    os.makedirs(base_results_dir, exist_ok=True)

    # --------------------------------------------------------
    # 7ï¸âƒ£ ëª¨ë¸ë³„ SHAP / LIME ìˆ˜í–‰
    # --------------------------------------------------------
    for model_name, model in models.items():

        print(f"ğŸ” Explain ì‹œì‘: {model_name}")

        explain_dir = os.path.join(
            base_results_dir,
            f"EXPLAIN_{model_name}"
        )
        os.makedirs(explain_dir, exist_ok=True)

        # ----------------------------------------------------
        # ëª¨ë¸ í•™ìŠµ (Explain ì „ìš© feature ì‚¬ìš©)
        # ----------------------------------------------------
        model.fit(X_explain, y)

        # ----------------------------------------------------
        # SHAP ë¶„ì„
        # ----------------------------------------------------
        run_shap_analysis(
            model=model,
            X_train=X_explain,
            X_test=X_explain,
            feature_names=feature_names,
            save_dir=explain_dir
        )

        # ----------------------------------------------------
        # LIME ë¶„ì„
        # ----------------------------------------------------
        run_lime_analysis(
            model=model,
            X_train=X_explain,
            X_test=X_explain,
            feature_names=feature_names,
            save_dir=explain_dir
        )

        print(f"âœ… SHAP/LIME ì™„ë£Œ: {model_name}")

    print(f"\nğŸ‰ Explain pipeline ì™„ë£Œ: {experiment_name}")


# ------------------------------------------------------------
# ë‹¨ë… ì‹¤í–‰ìš©
# ------------------------------------------------------------
if __name__ == "__main__":

    run_explain_pipeline(
        data_path="data/dataset.csv",   # â­ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€
        experiment_name="SG_PLUS_META",
        target_models=["LightGBM", "RandomForest"]
    )
