# pipelines/explain_pipeline.py
# ============================================================
# SHAP / LIME Explainability ì „ìš© íŒŒì´í”„ë¼ì¸
# ============================================================

import os # íŒŒì¼/í´ë” ê²½ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd # DataFrame ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np # ìˆ˜ì¹˜ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬

from src.preprocessing import preprocess_and_filter_outliers # í•™ìŠµ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬/ì´ìƒì¹˜ ì œê±° ë¡œì§ ì¬ì‚¬ìš©
from src.models import get_model_dict # ë™ì¼í•œ ëª¨ë¸ êµ¬ì„± ì¬ì‚¬ìš©
from src.explainability import run_shap_analysis, run_lime_analysis # SHAP / LIME ë¶„ì„ í•¨ìˆ˜


# ============================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ê³„ì‚°
# ============================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ============================================================
# Explain ì „ìš© One-Hot Feature ìƒì„± í•¨ìˆ˜
# ============================================================
CATEGORICAL_COLS = [
    "Meal_Status",
    "BMI_Class",
    "Age_Group",
    "Exercise",
    "Family_History",
    "Pregnancy",
]


def build_explain_features(df: pd.DataFrame): # Explain ì „ìš© Feature ìƒì„± í•¨ìˆ˜
    """
    SHAP / LIME ì „ìš© feature ìƒì„±

    - SG: ìˆ˜ì¹˜í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ë²”ì£¼í˜• ë³€ìˆ˜: One-Hot Encoding
    - í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸ê³¼ ë¶„ë¦¬ëœ Explain ì „ìš© ì„¤ê³„
    """

    # --------------------------------------------------------
    # 1ï¸âƒ£ ìˆ˜ì¹˜í˜• Feature
    # --------------------------------------------------------
    X_num = df[["SG"]]

    # --------------------------------------------------------
    # 2ï¸âƒ£ ë²”ì£¼í˜• Feature â†’ One-Hot Encoding
    # --------------------------------------------------------
    X_cat = pd.get_dummies(
        df[CATEGORICAL_COLS],
        prefix=CATEGORICAL_COLS
    )

    # --------------------------------------------------------
    # 3ï¸âƒ£ ê²°í•©
    # --------------------------------------------------------
    X_explain = pd.concat([X_num, X_cat], axis=1)

    feature_names = X_explain.columns.tolist()

    return X_explain.values, feature_names


def run_explain_pipeline( # explainability íŒŒì´í”„ë¼ì¸ ë©”ì¸ í•¨ìˆ˜
    data_path: str,
    experiment_name: str,
    target_models: list | None = None
):

    # --------------------------------------------------------
    # 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
    # --------------------------------------------------------
    data_path = os.path.join(BASE_DIR, data_path)
    df = pd.read_csv(data_path)

    # --------------------------------------------------------
    # 2ï¸âƒ£ ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
    # --------------------------------------------------------
    drop_cols = [c for c in ["Gender", "Target_R"] if c in df.columns]
    df = df.drop(columns=drop_cols)

    # --------------------------------------------------------
    # 3ï¸âƒ£ ì „ì²˜ë¦¬ + ì´ìƒì¹˜ ì œê±°
    # --------------------------------------------------------
    df_clean, _ = preprocess_and_filter_outliers(df)

    # index ì •ë¦¬
    df_clean = df_clean.reset_index(drop=True)

    # --------------------------------------------------------
    # 4ï¸âƒ£ Explain ì „ìš© Feature êµ¬ì„± (One-Hot)
    # --------------------------------------------------------
    # íƒ€ê¹ƒ
    y = df_clean["BG"].values

    # Explain ì „ìš© Feature
    X_explain, feature_names = build_explain_features(df_clean)

    # --------------------------------------------------------
    # 5ï¸âƒ£ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    # --------------------------------------------------------
    models = get_model_dict()

    if target_models is not None:
        models = {
            name: model
            for name, model in models.items()
            if name in target_models
        }

    # --------------------------------------------------------
    # â— Ensemble ëª¨ë¸ì€ Explain ëŒ€ìƒì—ì„œ ì œì™¸
    # --------------------------------------------------------
    if "Ensemble" in models:
        print("âš ï¸ Ensemble ëª¨ë¸ì€ SHAP/LIME ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")
        models.pop("Ensemble")

    # --------------------------------------------------------
    # 6ï¸âƒ£ Explain ê²°ê³¼ ì €ì¥ ë£¨íŠ¸
    # --------------------------------------------------------
    base_results_dir = os.path.join(
        BASE_DIR,
        "results",
        experiment_name
    )
    os.makedirs(base_results_dir, exist_ok=True)

    # --------------------------------------------------------
    # 7ï¸âƒ£ ëª¨ë¸ë³„ SHAP / LIME ìˆ˜í–‰
    # --------------------------------------------------------
    for model_name, model in models.items():

        print(f"ğŸ” Explain ì‹œì‘: {model_name}")

        explain_dir = os.path.join(
            base_results_dir,
            f"EXPLAIN_{model_name}"
        )
        os.makedirs(explain_dir, exist_ok=True)

        # ----------------------------------------------------
        # ëª¨ë¸ í•™ìŠµ (Explain ì „ìš© feature ì‚¬ìš©)
        # ----------------------------------------------------
        model.fit(X_explain, y)

        # ----------------------------------------------------
        # SHAP ë¶„ì„
        # ----------------------------------------------------
        run_shap_analysis(
            model=model,
            X_train=X_explain,
            X_test=X_explain,
            feature_names=feature_names,
            save_dir=explain_dir
        )

        # ----------------------------------------------------
        # LIME ë¶„ì„
        # ----------------------------------------------------
        run_lime_analysis(
            model=model,
            X_train=X_explain,
            X_test=X_explain,
            feature_names=feature_names,
            save_dir=explain_dir
        )

        print(f"âœ… SHAP/LIME ì™„ë£Œ: {model_name}")

    print(f"\nğŸ‰ Explain pipeline ì™„ë£Œ: {experiment_name}")


# ------------------------------------------------------------
# ë‹¨ë… ì‹¤í–‰ìš© ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ------------------------------------------------------------
if __name__ == "__main__":

    run_explain_pipeline(
        data_path="data/dataset.csv",   # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
        experiment_name="SG_PLUS_META",
        target_models=[
            "LightGBM",
            "RandomForest",
            "XGBoost",
            "CatBoost"
        ]
    )
